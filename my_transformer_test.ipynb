{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_transformer import Transformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from word_mapping import word_mapping\n",
    "from tag_mapping import tag_mapping\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "language = 'English'\n",
    "train_data, valid_data = get_data_set(language)\n",
    "TagMapping = tag_mapping(language)\n",
    "WordMapping = word_mapping(train_data)\n",
    "train_data.get_tag_mapping(TagMapping.encode_mapping)\n",
    "train_data.get_word_mapping(WordMapping.encode_mapping)\n",
    "valid_data.get_tag_mapping(TagMapping.encode_mapping)\n",
    "valid_data.get_word_mapping(WordMapping.encode_mapping)\n",
    "tag_size = TagMapping.num_tag\n",
    "vocab_size = WordMapping.num_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_embed = 100\n",
    "max_len = 300\n",
    "num_heads = 5\n",
    "dim_feedforward = 400\n",
    "dropout = 0\n",
    "num_encoder = 6\n",
    "dim_out = tag_size\n",
    "\n",
    "lr = 0.001\n",
    "max_epoch = 20\n",
    "batch_size = 16\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Transformer(\n",
    "    dim_embed,\n",
    "    vocab_size,\n",
    "    max_len,\n",
    "    num_encoder,\n",
    "    num_heads,\n",
    "    dim_feedforward,\n",
    "    dim_out,\n",
    "    dropout)\n",
    "    \n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:18, 48.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.19956177348750462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 55.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.11108615746878614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, loss: 0.07672787645029791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, loss: 0.05636093800925652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, loss: 0.044960459153823434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, loss: 0.036904211694922015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 57.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, loss: 0.031616593195827665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, loss: 0.028366923281829593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, loss: 0.026536352305626922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 55.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, loss: 0.022897199987407864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 55.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.021601729594586856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, loss: 0.01938380400720742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, loss: 0.018651901925127723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, loss: 0.018495793857791775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, loss: 0.016961502086004967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, loss: 0.015312478304510472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, loss: 0.015494537625169055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, loss: 0.01493827163475894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, loss: 0.014777711498308959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:15, 56.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, loss: 0.014467934739472586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(max_epoch):\n",
    "    loss_sum = 0\n",
    "    num = 0\n",
    "    for sentences, tags in tqdm(batch_iter(train_data, batch_size=batch_size)):\n",
    "        sentences, sent_lengths = pad(sentences, vocab_size - 1, device)\n",
    "        tags, _ = pad(tags, tag_size - 1, device)\n",
    "\n",
    "        mask_sentences = torch.ones_like(sentences)\n",
    "        mask_sentences[sentences == vocab_size - 1] = 0\n",
    "        mask_tags = torch.ones_like(tags)\n",
    "        mask_tags[tags == tag_size - 1] = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(sentences, mask_sentences)\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        loss = loss_fn(output, tags)\n",
    "        loss_sum += loss.item()\n",
    "        num += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch: {epoch}, loss: {loss_sum / num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3250/3250 [00:19<00:00, 164.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.8181    0.6471    0.7226      1842\n",
      "       I-PER     0.7669    0.4430    0.5616      1307\n",
      "       B-ORG     0.7916    0.6428    0.7095      1341\n",
      "       I-ORG     0.7553    0.5260    0.6201       751\n",
      "       B-LOC     0.8748    0.7681    0.8180      1837\n",
      "       I-LOC     0.7311    0.6770    0.7030       257\n",
      "      B-MISC     0.8692    0.7354    0.7967       922\n",
      "      I-MISC     0.8009    0.5347    0.6412       346\n",
      "\n",
      "   micro avg     0.8190    0.6365    0.7163      8603\n",
      "   macro avg     0.8010    0.6218    0.6966      8603\n",
      "weighted avg     0.8150    0.6365    0.7116      8603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from check import *\n",
    "\n",
    "\n",
    "my_path = f\"my_{language}_transformer_result.txt\"\n",
    "file = open(my_path, \"w\")\n",
    "for words, tags in tqdm(valid_data):\n",
    "    mask = torch.ones(len(words)).unsqueeze(0).to(device)\n",
    "    torch_words = torch.tensor(words, dtype=torch.long, device=device).unsqueeze(0)\n",
    "    tags_pred = model.predict(torch_words, mask)\n",
    "    tags_pred = torch.flatten(tags_pred).tolist()\n",
    "    words_decoded = WordMapping.decode(words)\n",
    "    tags_decoded = TagMapping.decode(tags_pred)\n",
    "    for i in range(len(words)):\n",
    "        file.write(f\"{words_decoded[i]} {tags_decoded[i]}\\n\")\n",
    "    file.write(\"\\n\")\n",
    "file.close()\n",
    "\n",
    "gold_path = f\"./NER/{language}/validation.txt\"\n",
    "check(language, gold_path, my_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
